{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7139992,"sourceType":"datasetVersion","datasetId":4120801}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy seqeval torch fairseq \"transformers[torch]\" datasets evaluate more_itertools sentencepiece protobuf\n!pip install -U transformers[torch] datasets evaluate accelerate tokenizers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-08T02:00:56.704865Z","iopub.execute_input":"2023-12-08T02:00:56.705482Z","iopub.status.idle":"2023-12-08T02:02:22.461464Z","shell.execute_reply.started":"2023-12-08T02:00:56.705456Z","shell.execute_reply":"2023-12-08T02:02:22.460538Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nCollecting fairseq\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: more_itertools in /opt/conda/lib/python3.10/site-packages (10.1.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (3.20.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.15.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq) (3.0.0)\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq)\n  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq) (2023.8.8)\nCollecting sacrebleu>=1.4.12 (from fairseq)\n  Obtaining dependency information for sacrebleu>=1.4.12 from https://files.pythonhosted.org/packages/0a/a6/2ac47e71e526bbcd97ea08f20d9ef7d3852e2594ec7b2d55f5d2bbfd7aae/sacrebleu-2.3.3-py3-none-any.whl.metadata\n  Downloading sacrebleu-2.3.3-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq) (4.66.1)\nCollecting bitarray (from fairseq)\n  Obtaining dependency information for bitarray from https://files.pythonhosted.org/packages/a6/6c/d8312e6bddbcfa2d0ad2b440b4ada1e19a6321389baa2261d2846b61d6f7/bitarray-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading bitarray-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\nRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.0.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.25.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.12.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nCollecting portalocker (from sacrebleu>=1.4.12->fairseq)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-2.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (279 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.9/279.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: seqeval, fairseq, antlr4-python3-runtime\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a527abdd818464b4e072f8b63eefa7d2c91d72d7f2267771d6d5a8f6b5cced97\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10415297 sha256=07b5e2cc7e0ed5dc37b9c38d44e8caa0370c7df71f8c4ca18400523e9beea8db\n  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=feab559470e2708e307f401f767ddea8be6a384263842ad9c2fa5f0cc2dc4c04\n  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built seqeval fairseq antlr4-python3-runtime\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, seqeval, fairseq, evaluate\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.8.4 evaluate-0.4.1 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.3 seqeval-1.2.2\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.35.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting datasets\n  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.15.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.19.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nCollecting pyarrow-hotfix (from datasets)\n  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nCollecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\n  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.11.17)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.1\n    Uninstalling fsspec-2023.12.1:\n      Successfully uninstalled fsspec-2023.12.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ns3fs 2023.12.1 requires fsspec==2023.12.1, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 fsspec-2023.10.0 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED']=\"true\"\nimport math\nimport evaluate\nimport numpy as np\nfrom random import sample\nfrom datasets import Dataset\nfrom functools import partial\nfrom itertools import groupby, chain\nfrom accelerate import notebook_launcher\nfrom more_itertools import split_at, chunked\nfrom transformers import (\n    AutoTokenizer,\n    DataCollatorForTokenClassification,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    pipeline,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:02:58.024643Z","iopub.execute_input":"2023-12-08T03:02:58.024956Z","iopub.status.idle":"2023-12-08T03:03:05.071761Z","shell.execute_reply.started":"2023-12-08T03:02:58.024930Z","shell.execute_reply":"2023-12-08T03:03:05.070961Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"label2id = {\n    \"B-repair_R\": 0,\n    \"I-repair_R\": 1,\n    \"B-filler_R\": 2,\n    \"I-filler_R\": 3,\n    \"B-repeat_R\": 4,\n    \"I-repeat_R\": 5,\n    \"B-edit_R\": 6,\n    \"I-edit_R\": 7,\n    \"B-false_R\": 8,\n    \"I-false_R\": 9,\n    \"B-pet_R\": 10,\n    \"I-pet_R\": 11,\n    \"B-Alteration\": 12,\n    \"I-Alteration\": 13,\n    \"O\": 14,\n}\nid2label = {v: k for k, v in label2id.items()}","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:05.077051Z","iopub.execute_input":"2023-12-08T03:03:05.077334Z","iopub.status.idle":"2023-12-08T03:03:05.083237Z","shell.execute_reply.started":"2023-12-08T03:03:05.077310Z","shell.execute_reply":"2023-12-08T03:03:05.082090Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def generate_examples(fnames, tokenizer):\n    for fname in fnames:\n        with open(fname, \"r\") as f:\n            for wordtags in (\n                [word.rstrip().rsplit(\"\\t\", maxsplit=1) for word in sent]\n                for sent in split_at(f, str.isspace)\n            ):\n                words = [word for word, _ in wordtags]\n                tags = [tag for _, tag in wordtags]\n                tokenized = tokenizer(words, is_split_into_words=True, truncation=True)\n                input_ids = tokenized[\"input_ids\"]\n                attention_mask = tokenized[\"attention_mask\"]\n                for i in range(math.ceil(len(input_ids) / 510)):\n                    _input_ids = (\n                        [input_ids[0]]\n                        + input_ids[1 + (i * 510) : 511 + (i * 510)]\n                        + [input_ids[-1]]\n                    )\n                    _attention_mask = (\n                        [attention_mask[0]]\n                        + attention_mask[1 + (i * 510) : 511 + (i * 510)]\n                        + [attention_mask[-1]]\n                    )\n                    _labels = list(\n                        chain.from_iterable(\n                            (\n                                [-100]\n                                if tokenid == None\n                                else (label2id[tags[tokenid]] for _ in inputids)\n                            )\n                            for tokenid, inputids in groupby(\n                                range(len(_input_ids)),\n                                key=lambda x: tokenized.token_to_word(\n                                    batch_or_token_index=x\n                                ),\n                            )\n                        )\n                    )\n\n                    yield {\n                        \"words\": words,\n                        \"tags\": tags,\n                        \"input_ids\": _input_ids,\n                        \"attention_mask\": _attention_mask,\n                        \"labels\": _labels,\n                    }","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:05.084576Z","iopub.execute_input":"2023-12-08T03:03:05.084947Z","iopub.status.idle":"2023-12-08T03:03:05.097545Z","shell.execute_reply.started":"2023-12-08T03:03:05.084915Z","shell.execute_reply":"2023-12-08T03:03:05.096699Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def random_cutter(examples):\n    for examplei in range(len(examples[\"input_ids\"])):\n        input_ids = examples[\"input_ids\"][examplei]\n        labels = examples[\"labels\"][examplei]\n        while True:\n            lo, hi = sorted(\n                sample(\n                    [\n                        i\n                        for i, label in enumerate(labels)\n                        if label == label2id[\"O\"] or label == -100\n                    ],\n                    2,\n                )\n            )\n            included_indices = [\n                i\n                for i in range(len(labels))\n                if i in range(lo, hi + 1) or labels[i] == -100\n            ]\n            if len(included_indices) <= 512:\n                break\n        examples[\"input_ids\"][examplei] = [input_ids[i] for i in included_indices]\n        examples[\"labels\"][examplei] = [labels[i] for i in included_indices]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:05.099557Z","iopub.execute_input":"2023-12-08T03:03:05.099849Z","iopub.status.idle":"2023-12-08T03:03:05.115431Z","shell.execute_reply.started":"2023-12-08T03:03:05.099822Z","shell.execute_reply":"2023-12-08T03:03:05.114481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(p, seqeval=evaluate.load(\"seqeval\")):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    true_predictions = [\n        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2label[l] for (_, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:05.116641Z","iopub.execute_input":"2023-12-08T03:03:05.116941Z","iopub.status.idle":"2023-12-08T03:03:05.855233Z","shell.execute_reply.started":"2023-12-08T03:03:05.116916Z","shell.execute_reply":"2023-12-08T03:03:05.854282Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"modelname = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(modelname)\ntrain_data = Dataset.from_generator(\n    partial(\n        generate_examples,\n        [\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Bengali/bengali_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Hindi/hindi_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Kannada/kannada_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Marathi/marathi_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Tamil/tamil_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Telugu/telugu_train.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Bengali/bengali_train_2.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Hindi/hindi_train_2.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Kannada/kannada_train_2.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Marathi/marathi_train_2.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Tamil/tamil_train_2.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-data-part2/Tamil/tamil_train_2.tsv\"\n            \n        ],\n        tokenizer,\n    )\n)\n# train_data.set_transform(random_cutter)\ndev_data = Dataset.from_generator(\n    partial(\n        generate_examples,\n        [\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Bengali/bengali_dev.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Hindi/hindi_dev.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Kannada/kannada_dev.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Marathi/marathi_dev.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Tamil/tamil_dev.tsv\",\n            \"/kaggle/input/disfluency-shared-task/Train-Dev-data-part1/Telugu/telugu_dev.tsv\"\n        ],\n        tokenizer\n    )\n)\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\nmodel = AutoModelForTokenClassification.from_pretrained(\n    modelname, num_labels=len(id2label), id2label=id2label, label2id=label2id\n)\ntrainingargs = TrainingArguments(\n    output_dir=\"training_outputs\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=15,\n    learning_rate=1e-5,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    save_total_limit=3,\n    fp16=True\n)\ntrainer = Trainer(\n    model=model,\n    args=trainingargs,\n    train_dataset=train_data,\n    eval_dataset=dev_data,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:05.856552Z","iopub.execute_input":"2023-12-08T03:03:05.856931Z","iopub.status.idle":"2023-12-08T03:03:18.769365Z","shell.execute_reply.started":"2023-12-08T03:03:05.856897Z","shell.execute_reply":"2023-12-08T03:03:18.768311Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e26a6eb91424caba1c3626ff9d1e105"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:03:18.770705Z","iopub.execute_input":"2023-12-08T03:03:18.771308Z","iopub.status.idle":"2023-12-08T04:59:13.875678Z","shell.execute_reply.started":"2023-12-08T03:03:18.771271Z","shell.execute_reply":"2023-12-08T04:59:13.874739Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27720' max='27720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27720/27720 1:55:54, Epoch 15/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.310100</td>\n      <td>0.237561</td>\n      <td>0.690789</td>\n      <td>0.643087</td>\n      <td>0.666085</td>\n      <td>0.933065</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.199100</td>\n      <td>0.190373</td>\n      <td>0.770347</td>\n      <td>0.788394</td>\n      <td>0.779266</td>\n      <td>0.950882</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.155000</td>\n      <td>0.157063</td>\n      <td>0.856842</td>\n      <td>0.809218</td>\n      <td>0.832349</td>\n      <td>0.961636</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.128900</td>\n      <td>0.150679</td>\n      <td>0.835844</td>\n      <td>0.815495</td>\n      <td>0.825544</td>\n      <td>0.958627</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.107600</td>\n      <td>0.155153</td>\n      <td>0.859323</td>\n      <td>0.862349</td>\n      <td>0.860833</td>\n      <td>0.966038</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.096600</td>\n      <td>0.172027</td>\n      <td>0.857383</td>\n      <td>0.860665</td>\n      <td>0.859020</td>\n      <td>0.965439</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.080700</td>\n      <td>0.174150</td>\n      <td>0.861694</td>\n      <td>0.849028</td>\n      <td>0.855314</td>\n      <td>0.966024</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.072300</td>\n      <td>0.162500</td>\n      <td>0.907670</td>\n      <td>0.844434</td>\n      <td>0.874911</td>\n      <td>0.969785</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.061300</td>\n      <td>0.167499</td>\n      <td>0.866071</td>\n      <td>0.861430</td>\n      <td>0.863745</td>\n      <td>0.965787</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.059700</td>\n      <td>0.187722</td>\n      <td>0.857986</td>\n      <td>0.867708</td>\n      <td>0.862820</td>\n      <td>0.965063</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.051900</td>\n      <td>0.194006</td>\n      <td>0.874826</td>\n      <td>0.864646</td>\n      <td>0.869706</td>\n      <td>0.968378</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.043700</td>\n      <td>0.207777</td>\n      <td>0.872478</td>\n      <td>0.867402</td>\n      <td>0.869932</td>\n      <td>0.967932</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.040700</td>\n      <td>0.221735</td>\n      <td>0.853472</td>\n      <td>0.869545</td>\n      <td>0.861433</td>\n      <td>0.965829</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.038400</td>\n      <td>0.218684</td>\n      <td>0.871168</td>\n      <td>0.861430</td>\n      <td>0.866271</td>\n      <td>0.967515</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.037100</td>\n      <td>0.219786</td>\n      <td>0.876578</td>\n      <td>0.861277</td>\n      <td>0.868860</td>\n      <td>0.967821</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27720, training_loss=0.1069612191869067, metrics={'train_runtime': 6954.7886, 'train_samples_per_second': 63.75, 'train_steps_per_second': 3.986, 'total_flos': 2.538292270771404e+16, 'train_loss': 0.1069612191869067, 'epoch': 15.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('final_model')","metadata":{"execution":{"iopub.status.busy":"2023-12-08T05:00:56.969140Z","iopub.execute_input":"2023-12-08T05:00:56.970041Z","iopub.status.idle":"2023-12-08T05:00:59.787656Z","shell.execute_reply.started":"2023-12-08T05:00:56.969994Z","shell.execute_reply":"2023-12-08T05:00:59.786580Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('final_model')\npipe = pipeline('ner', model=model, tokenizer=tokenizer)\nfor lang in ['Bengali', 'Hindi', 'Kannada', 'Marathi', 'Tamil', 'Telugu']:\n    with open(f'/kaggle/input/disfluency-shared-task/Test-Blind/{lang}/{lang.lower()}_test_blind.tsv', 'r') as f: words = list(map(str.strip, f))\n    texts = [' '.join(w) for w in chunked(words, 200)]\n    with open(f'{lang.lower()}_out.tsv', 'w') as f:\n        for text in texts:\n            text_tokenized = tokenizer(text)\n            words = text.split(' ')\n            tags = ['O']*len(words)\n            outs = pipe([text])\n            for out in outs[0]: tags[text_tokenized.token_to_word(batch_or_token_index=out['index'])] = out['entity']\n            for a, b in zip(words, tags): f.write(f'{a}\\t{b}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-12-08T05:35:36.396937Z","iopub.execute_input":"2023-12-08T05:35:36.397342Z","iopub.status.idle":"2023-12-08T05:38:23.733265Z","shell.execute_reply.started":"2023-12-08T05:35:36.397309Z","shell.execute_reply":"2023-12-08T05:38:23.732091Z"},"trusted":true},"execution_count":89,"outputs":[]}]}